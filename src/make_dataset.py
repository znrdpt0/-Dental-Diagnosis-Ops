import json
import shutil
from pathlib import Path
import cv2
import numpy as np
from tqdm import tqdm  # Ä°lerleme Ã§ubuÄŸu iÃ§in

# --- AYARLAR ---
# Proje kÃ¶k dizinini bul (src klasÃ¶rÃ¼nden bir Ã¼st dizine Ã§Ä±k)
BASE_DIR = Path(__file__).resolve().parent.parent

# Ham Veri YollarÄ± (Senin LS Ã§Ä±ktÄ±larÄ±na gÃ¶re)
RAW_DATA_DIR = BASE_DIR / "data/raw/DENTEX"

# Train YollarÄ±
TRAIN_INPUT_DIR = RAW_DATA_DIR / "train/training_data/quadrant-enumeration-disease"
TRAIN_JSON = TRAIN_INPUT_DIR / "train_quadrant_enumeration_disease.json"
TRAIN_IMAGES = TRAIN_INPUT_DIR / "xrays"

# Val YollarÄ± (Dikkat: Val klasÃ¶rÃ¼nde tire yerine alt Ã§izgi kullanÄ±lmÄ±ÅŸtÄ±)
VAL_INPUT_DIR = RAW_DATA_DIR / "val/validation_data/quadrant_enumeration_disease"
# Val JSON dosyasÄ± ana dizindeydi, onu buraya referans veriyoruz
VAL_JSON = RAW_DATA_DIR / "validation_triple.json" 
VAL_IMAGES = VAL_INPUT_DIR / "xrays"

# Hedef KlasÃ¶r
PROCESSED_DIR = BASE_DIR / "data/processed"
IMG_SIZE = 640  # YOLO standart boyutu

# SÄ±nÄ±f HaritasÄ± (Validation JSON'dan Ã¶ÄŸrendiÄŸimiz hastalÄ±k ID'leri)
# YOLO sÄ±nÄ±f ID'leri 0'dan baÅŸlamalÄ±dÄ±r.
CLASS_MAPPING = {
    0: 0, # Impacted
    1: 1, # Caries
    2: 2, # Periapical Lesion
    3: 3  # Deep Caries
}

def setup_directories():
    """YOLO klasÃ¶r yapÄ±sÄ±nÄ± oluÅŸturur."""
    for split in ['train', 'val']:
        (PROCESSED_DIR / split / 'images').mkdir(parents=True, exist_ok=True)
        (PROCESSED_DIR / split / 'labels').mkdir(parents=True, exist_ok=True)
    print(f"âœ… KlasÃ¶r yapÄ±sÄ± hazÄ±r: {PROCESSED_DIR}")

def convert_bbox_to_yolo(bbox, img_width, img_height):
    """COCO bbox (x_min, y_min, w, h) -> YOLO bbox (x_center, y_center, w, h) normalize."""
    x_min, y_min, w, h = bbox
    
    x_center = (x_min + w / 2) / img_width
    y_center = (y_min + h / 2) / img_height
    width = w / img_width
    height = h / img_height
    
    return x_center, y_center, width, height

def resize_image_letterbox(image, target_size):
    """Resmi bozmadan (aspect ratio koruyarak) target_size'a sÄ±ÄŸdÄ±rÄ±r ve padding ekler."""
    h, w = image.shape[:2]
    scale = min(target_size / w, target_size / h)
    nw, nh = int(w * scale), int(h * scale)
    
    image_resized = cv2.resize(image, (nw, nh))
    
    # Padding (Dolgu) oluÅŸtur
    image_padded = np.full((target_size, target_size, 3), 128, dtype=np.uint8) # Gri dolgu
    
    # Resmi merkeze yerleÅŸtir
    dx = (target_size - nw) // 2
    dy = (target_size - nh) // 2
    image_padded[dy:dy+nh, dx:dx+nw] = image_resized
    
    return image_padded, scale, dx, dy

def process_dataset(json_path, image_dir, split_name):
    """Verilen veri setini iÅŸler, dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r ve kaydeder."""
    print(f"\nğŸš€ {split_name.upper()} veri seti iÅŸleniyor...")
    
    # JSON YÃ¼kle
    with open(json_path, 'r') as f:
        data = json.load(f)
        
    # Resim ID'lerine gÃ¶re dosya isimlerini eÅŸleÅŸtir
    img_dict = {img['id']: img for img in data['images']}
    
    # AnotasyonlarÄ± resim ID'sine gÃ¶re grupla
    ann_dict = {}
    for ann in data['annotations']:
        img_id = ann['image_id']
        if img_id not in ann_dict:
            ann_dict[img_id] = []
        ann_dict[img_id].append(ann)
        
    # Ä°ÅŸlem dÃ¶ngÃ¼sÃ¼
    for img_id, img_info in tqdm(img_dict.items()):
        file_name = img_info['file_name']
        src_path = image_dir / file_name
        
        # Resim dosyasÄ±nÄ± kontrol et
        if not src_path.exists():
            # Bazen dosya isimleri json ile diskte uyuÅŸmayabilir, basit bir kontrol
            continue
            
        # 1. RESMÄ° OKU VE BOYUTLANDIR
        img = cv2.imread(str(src_path))
        if img is None:
            continue
            
        img_h, img_w = img.shape[:2]
        processed_img, scale, dx, dy = resize_image_letterbox(img, IMG_SIZE)
        
        # 2. ANOTASYONLARI Ä°ÅLE
        yolo_labels = []
        if img_id in ann_dict:
            for ann in ann_dict[img_id]:
                # Sadece HastalÄ±k (Diagnosis) kategorisini al (category_id_3)
                cat_id = ann.get('category_id_3')
                
                # EÄŸer hastalÄ±k ID'si bizim haritamÄ±zda varsa iÅŸle
                if cat_id in CLASS_MAPPING:
                    class_id = CLASS_MAPPING[cat_id]
                    bbox = ann['bbox'] # x, y, w, h
                    
                    # Orijinal bbox'Ä± resize iÅŸlemine gÃ¶re gÃ¼ncelle
                    # (Resmi kÃ¼Ã§Ã¼lttÃ¼k ve padding ekledik, kutular da kaymalÄ±)
                    x = bbox[0] * scale + dx
                    y = bbox[1] * scale + dy
                    w = bbox[2] * scale
                    h = bbox[3] * scale
                    
                    # YOLO formatÄ±na Ã§evir (Normalize et)
                    xc, yc, nw, nh = convert_bbox_to_yolo((x, y, w, h), IMG_SIZE, IMG_SIZE)
                    
                    yolo_labels.append(f"{class_id} {xc:.6f} {yc:.6f} {nw:.6f} {nh:.6f}")
        
        # 3. KAYDET
        # Resmi kaydet
        save_img_path = PROCESSED_DIR / split_name / 'images' / file_name
        cv2.imwrite(str(save_img_path), processed_img)
        
        # Etiketi kaydet (EÄŸer etiket varsa)
        if yolo_labels:
            label_name = Path(file_name).stem + ".txt"
            save_label_path = PROCESSED_DIR / split_name / 'labels' / label_name
            with open(save_label_path, 'w') as f:
                f.write("\n".join(yolo_labels))

if __name__ == "__main__":
    setup_directories()
    
    # Ã–nce Validation setini iÅŸle (Daha kÃ¼Ã§Ã¼k, test iÃ§in iyi)
    if VAL_JSON.exists() and VAL_IMAGES.exists():
        process_dataset(VAL_JSON, VAL_IMAGES, 'val')
    else:
        print("âŒ Val dosyalarÄ± bulunamadÄ±, atlanÄ±yor.")

    # Sonra Train setini iÅŸle
    if TRAIN_JSON.exists() and TRAIN_IMAGES.exists():
        process_dataset(TRAIN_JSON, TRAIN_IMAGES, 'train')
    else:
        print(f"âŒ Train dosyalarÄ± bulunamadÄ±: {TRAIN_JSON}")